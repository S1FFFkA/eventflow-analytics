# eventflow-analytics
Система для сбора ,обработки , обогащения , хранения и визуализации событий от веб и мобильных приложений .
# тз 
Gleb Barinov, [25.12.2025 2:07]
Архитектура и микросервисы (2-3 разработчика)
Каждый микросервис — отдельный Go-модуль, общающийся через Kafka.
Event Ingestion Service (Прием событий)
Назначение: Публичный HTTP endpoint (REST/gRPC), принимающий события от клиентов (с валидацией).
Стек: Go (chi/gin), валидация структур.
Работа с Kafka: Записывает валидированные сырые события в топик Kafka raw_events. Это точка входаданных.
Метрики Prometheus: Кол-во входящих запросов, ошибки валидации, latency.
Event Processing & Enrichment Service (Обработка и обогащение)
Назначение: Читает raw_events, обогащает их (добавляет geo-данные по IP, информацию о user-agent, нормализует данные). Фильтрует или маскирует чувствительные данные.
Стек: Go, Kafka Consumer/Producer, возможно внешние API для геолокации.
Работа с Kafka: Читает raw_events, пишет обогащенные события в топик enriched_events.
Работа с Redis: Кеширование результатов внешних запросов (например, гео-данные по IP) для скорости и снижения нагрузки на внешние API.
Event Sink & Storage Service (Сохранение в хранилища)
Назначение: Читает enriched_events и сохраняет их в два хранилища параллельно.
Стек: Go, Kafka Consumer, ClickHouse, PostgreSQL.
Работа с БД:
PostgreSQL: Сохраняет только критически важные события для бизнес-логики (например, purchase, signup) в нормализованном виде для операционных нужд (отчеты в админке, интеграции). Использует связи между таблицами (users, events, products).
ClickHouse: Сохраняет ВСЕ события в денормализованном виде, оптимизированном для аналитических запросов (высокая скорость вставки и агрегации по времени). Это основное хранилище для аналитики.
Это самый нагруженный сервис с точки зрения работы с БД.
Query & Aggregation Service (API для агрегаций) [Опционально, если хватит времени]
Назначение: Предоставляет внутренний API для выполнения предопределенных аналитических запросов (например, "DAU за последние 7 дней", "конверсия по воронке").
Стек: Go, ClickHouse client.
Работа: Выполняет тяжелые агрегирующие запросы к ClickHouse, кеширует частые результаты в Redis, возвращает JSON.

Инфраструктурные компоненты
Kafka: Центральная нервная система. Топики: raw_events, enriched_events. Настройка репликации, партиционирования.
PostgreSQL: Таблицы для пользователей, сессий, ключевых событий.
ClickHouse: Одна большая таблица с событиями (event_table) с движком MergeTree, партиционированная по дате.
Redis: Кеш для сервиса обогащения и (опционально) для сервиса агрегаций.
Prometheus: Сбор метрик со всех Go-сервисов (количество обработанных событий, ошибки, latency, статусы подключений к БД/Kafka).
Grafana:
Дашборд #1 (Мониторинг системы):Графики потоков событий в Kafka (лаг потребления), ошибки, задержки обработки, нагрузка на БД.
Дашборд #2 (Бизнес-аналитика):Визуализация данных из ClickHouse: DAU/MAU, популярные события, конверсии (используются прямые SQL-запросы к ClickHouse из Grafana).

План работ на 1-2 месяца (по спринтам)
Неделя 1-2: Прототип и базовая цепочка
Настройка инфраструктуры (docker-compose для всех компонентов).
Event Ingestion Service: простой HTTP endpoint, запись в Kafka.
Event Sink Service: чтение из Kafka и запись в PostgreSQL и ClickHouse (сырые данные).
Первые метрики в Prometheus.
Неделя 3-4: Обработка и обогащение
Разработка Event Processing & Enrichment Service.
Интеграция Redis для кеширования.
Создание базовых Grafana-дашбордов для мониторинга.
Неделя 5-6: Масштабирование и отказоустойчивость
Рефакторинг, обработка ошибок, retry-логика для Kafka.
Настройка партиционирования в Kafka.
Оптимизация запросов к ClickHouse/PostgreSQL.
Добавление health-check эндпоинтов.
Неделя 7-8: Доработки и аналитика
Разработка опционального Query & Aggregation Service.
Создание бизнес-дашбордов в Grafana (аналитика из ClickHouse).
Нагрузочное тестирование, тюнинг, документация.

Почему этот проект идеален?
Покрывает весь стек: Каждый инструмент используется по назначению.
Ясное разделение обязанностей: Каждый микросервис — логичная единица работы. Разработчики могут распределить сервисы между собой.

Gleb Barinov, [25.12.2025 2:07]
Реальные проблемы: Нужно думать о согласованности данных, идемпотентности, форматах сообщений (Avro/Protobuf?), скорости обработки.
Масштабируемость: Легко представить, как каждый сервис масштабируется горизонтально.
Визуализируемый результат: Есть не только код, но и понятные дашборды в Grafana, что очень приятно и наглядно.
Портфолио-френдли: Проект решает актуальную задачу, его архитектуру можно красиво нарисовать и рассказать на собеседовании.
Вариант усложнения (если все будет делаться слишком быстро): Добавить второй консьюмер из топика enriched_events для отправки событий в вебхуки (внешние системы) или для реaltime-оповещений(например, в Telegram) о критических событиях (например, purchase > $1000).

















Можно подробнее о сути проекта . Что выполняет и делает приложение в целом






Отличный вопрос! Давайте разберем суть проекта на конкретном примере, чтобы было абсолютно ясно, что делает система и какую бизнес-проблему она решает.
Реальная аналогия: Умная аналитика для интернет-магазина "GadgetStore"
Представьте, что у вас есть интернет-магазин электроники. У вас есть:
Веб-сайт (React/Vue)
Мобильное приложение (iOS/Android)
Команда маркетинга, которая хочет понимать поведение пользователей
Команда продукта, которая хочет улучшать интерфейс
Техническая команда, которой нужен мониторинг

Что происходит в приложении (со стороны пользователя):
Анна заходит на сайт GadgetStore → система фиксирует событие page_view: "/home"
Она ищет "беспроводные наушники" → search_query: "беспроводные наушники"
Кликает на продукт "AirSound Pro" → product_click: "AirSound Pro"
Добавляет его в корзину → add_to_cart: {product_id: 123, price: 199.99}
Оформляет заказ → purchase: {order_id: 789, total: 199.99, items: [...]}
В мобильном приложении она ставит оценку → review: {product_id: 123, rating: 5}
Каждое из этих действий — событие (event).Их тысячи каждую минуту.

Что делает наша система EventFlow Analytics:
Фаза 1: Сбор данных (начинается за 1-2 недели)
text
[Веб-сайт] → HTTP → [Event Ingestion Service] → Kafka → [Сырые данные]
[Мобильное приложение] ↗
Конкретная задача для команды:
Создать надежный "входной шлюз", который принимает события
Гарантировать, что ни одно событие не потеряется при высокой нагрузке
Пример кода endpoint'а:
go
// POST /api/v1/event
{
  "user_id": "user_789",
  "session_id": "sess_xyz123",
  "event_type": "add_to_cart",
  "event_data": {"product_id": 123, "price": 199.99},
  "timestamp": "2024-03-15T10:30:00Z",
  "platform": "web",
  "url": "/products/123"
}
Фаза 2: Обработка и обогащение (недели 2-4)
Проблема: Сырые данные недостаточно информативны.
Наша система обогащает их:
text
Сырое событие: "user_789 кликнул на продукт 123 с IP 85.214.132.64"
↓
Обогащенное событие: 
"user_789 (премиум-пользователь из Москвы, зашел с iPhone Chrome)
кликнул на продукт 123 (категория: Аудио, цена: $199)
в 10:30 утра во время маркетинговой кампании 'Весенние скидки'"
Как это технически происходит:
Сервис обработки читает сырые события из Kafka
Смотрит IP 85.214.132.64 → определяет город (Москва) через Geolocation API
Кеширует результат в Redis, чтобы не дергать API для каждого запроса
Смотрит user_id → запрашивает из PostgreSQL, что это премиум-пользователь
Смотрит заголовки браузера → определяет устройство и браузер
Добавляет контекст маркетинга (из какой рекламы пришел пользователь)
Отправляет обогащенное событие обратно в Kafka
Фаза 3: Хранение для разных целей (недели 3-6)
В PostgreSQL сохраняются ТОЛЬКО бизнес-критичные события:
sql
-- Таблица purchases
id | user_id | product_id | amount | status | created_at
---|---------|------------|--------|--------|-----------
1  | user_789| 123        | 199.99 | paid   | 2024-03-15 10:35:00

-- Это нужно для:
-- 1. Формирования чеков
-- 2. Отображения истории заказов в личном кабинете
-- 3. Интеграции с бухгалтерской системой
В ClickHouse сохраняется ВСЁ для аналитики:
sql
-- Единая большая таблица events
timestamp           | user_id | event_type | event_data                                   | city    | device

Gleb Barinov, [25.12.2025 2:07]
-------------------|---------|------------|---------------------------------------------|---------|--------
2024-03-15 10:30:00| user_789| page_view  | {url: "/home"}                              | Москва  | iPhone
2024-03-15 10:31:00| user_789| search     | {query: "беспроводные наушники"}            | Москва  | iPhone
2024-03-15 10:32:00| user_789| product_view|{product_id: 123, category: "Аудио"}       | Москва  | iPhone
-- Миллиарды строк, оптимизированных для быстрых запросов
Почему два хранилища?
PostgreSQL: Точно, надежно, поддерживает транзакции (нельзя дважды списать деньги)
ClickHouse: Невероятно быстро (секунды) считает агрегации по миллиардам строк
Фаза 4: Аналитика и визуализация (недели 6-8)
Дашборд в Grafana для маркетинг-команды:
"Эффективность рекламной кампании 'Весенние скидки'"
DAU (Daily Active Users): 12,450 пользователей сегодня (+15% к прошлой неделе)
Конверсия в покупку: 3.2% (пользователь просмотрел → добавил в корзину → купил)
Средний чек: $187 (вырос на $22 после запуска кампинии)
География заказов: Москва (42%), СПб (18%), Новосибирск (7%)
Самые популярные товары: AirSound Pro (312 продаж), SmartWatch X (287)
Дашборд для техлида:
"Мониторинг здоровья системы"
Загрузка Kafka: 85,000 событий/минуту, лаг потребления < 100 мс
Ошибки валидации: 0.03% от общего трафика
Время ответа Ingestion Service: p95 < 50 мс
Нагрузка на ClickHouse: 45%, запросы выполняются за 200-800 мс

Какие конкретные бизнес-вопросы решает система:
Для продукт-менеджера:
Вопрос: "Упала ли конверсия после того, как мы поменяли кнопку 'Купить' с зеленой на синюю?"
Ответ: Grafana показывает: "Конверсия на страницах товаров упала с 4.2% до 3.1% за последние 24 часа".
Для маркетолога:
Вопрос: "Какая рекламная кампания приносит больше всего покупателей из Москвы?"
Ответ: Из ClickHouse: "Кампания в Яндекс.Директ дает CPA $12, а в Google Ads — $18".
Для техлида:
Вопрос: "Почему вчера вечером были проблемы с оформлением заказов?"
Ответ: В Grafana виден пик ошибок в Event Ingestion Service в 19:45, коррелирующий с DDoS-атакой.
Для аналитика:
Вопрос: "Как ведут себя пользователи, которые впервые зашли с мобильного?"
Ответ: "47% совершают покупку в течение 7 дней, средний LTV — $245".

Что делает приложение В ЦЕЛОМ:
Принимает поток событий от всех клиентских приложений
Очищает и обогащает эти события контекстом
Надежно сохраняет их в оптимальные хранилища
Позволяет в реальном времени следить за здоровьем системы
Дает возможность аналитикам отвечать на сложные бизнес-вопросы за секунды, а не за часы
Техническая аналогия: Это как построить центральную нервную систему для цифрового бизнеса, где:
Kafka — спинной мозг (передает сигналы)
Go-микросервисы — нейроны (обрабатывают сигналы)
PostgreSQL/ClickHouse — долговременная и кратковременная память
Grafana — зрительная кора (визуализирует информацию)
Проект решает реальные production-проблемы любого растущего digital-продукта и идеально ложится на ваш стек технологий!
